{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbpresent": {
     "id": "a47fa6c9-af4d-43f4-adc4-f30644aae2c1"
    }
   },
   "outputs": [],
   "source": [
    "#header\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def show(img,cvt=1):\n",
    "    img = np.uint8(img)\n",
    "    if cvt:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    return\n",
    "    \n",
    "def prin(sth):\n",
    "    print(sth)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "d3a70d6f-ba2c-41d7-a07c-16dbd4d237a7"
    }
   },
   "outputs": [],
   "source": [
    "#calculates the camera distortion\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "h_chessboard = 6\n",
    "b_chessboard = 9\n",
    "\n",
    "objp = np.zeros((h_chessboard*b_chessboard,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:b_chessboard, 0:h_chessboard].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    #prin(fname)\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #show(gray)\n",
    "    #prin(idx)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (b_chessboard,h_chessboard), None)\n",
    "    #prin(corners)\n",
    "    #prin(ret)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)   \n",
    "\n",
    "img_size = img.shape[:2]\n",
    "# Do camera calibration given object points and image points  \n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/dist_pickle.p\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f13ac75e-75b0-4c4f-9dad-ad9fb706bf8d"
    }
   },
   "outputs": [],
   "source": [
    "# undistort the test images\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('output_images/undist' + str(idx) + '.jpg',undist)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#process with gradient thresholds i\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return dir_binary\n",
    "\n",
    "def process_grad_thresholds(image):\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 9 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(30, 255))\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=15, mag_thresh=(30, 255))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined1 = np.zeros_like(dir_binary)\n",
    "    combined2 = np.zeros_like(dir_binary)\n",
    "    combined3 = np.zeros_like(dir_binary)\n",
    "    combined1[(gradx == 1)] = 1\n",
    "    combined2[((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined3 = cv2.bitwise_or(combined1, combined2)\n",
    "    #combined = np.uint8(np.rint(combined3*255))\n",
    "    combined = combined3\n",
    "    \n",
    "#    show(gradx,0)\n",
    "#    show(grady,0)\n",
    "#   show(mag_binary,0)\n",
    "#    show(dir_binary,0)\n",
    "#    show(combined,0)\n",
    "    row1 = np.concatenate((image,cv2.cvtColor(gradx*255,cv2.COLOR_GRAY2BGR)),axis=1)\n",
    "    row2 = np.concatenate((mag_binary,dir_binary),axis=1)\n",
    "    row2 = np.uint8(np.rint(row2*255))\n",
    "    row2 = cv2.cvtColor(row2,cv2.COLOR_GRAY2BGR)\n",
    "    row3 = np.concatenate((combined2,combined3),axis=1)\n",
    "    row3 = np.uint8(np.rint(row3*255))\n",
    "    row3 = cv2.cvtColor(row3,cv2.COLOR_GRAY2BGR)\n",
    "    processed_analyse = np.concatenate((row1,row2,row3),axis=0)\n",
    "    \n",
    "#    show(processed_analyse)\n",
    "    return processed_analyse, combined\n",
    "\n",
    "images = glob.glob('output_images/undist*.jpg')\n",
    "for idx,fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    processed_analyse, mask_grad_thres = process_grad_thresholds(img)\n",
    "    cv2.imwrite('output_images/processed_' + str(idx) + '.jpg', processed_analyse)\n",
    "    cv2.imwrite('output_images/mask_grad_thres_' + str(idx) + '.jpg', mask_grad_thres*255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pipeline adds color threshold\n",
    "#sx_thresh is not needed here, was for gradient threshold\n",
    "\n",
    "def color_thresh(img, s_thresh=(170, 255), l_thresh=(170, 255)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "        \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    return s_binary, l_binary\n",
    "\n",
    "def combine_grad_color_thresh(img):\n",
    "    analyse_grad,grad_binary=process_grad_thresholds(img)\n",
    "    s_binary, l_binary = color_thresh(img)\n",
    "    \n",
    "    rgb_combined = np.dstack(( np.zeros_like(grad_binary), grad_binary, s_binary)) * 255\n",
    "    binary_combined = np.zeros_like(grad_binary)\n",
    "    binary_combined[(grad_binary == 1) | (s_binary == 1)] = 1\n",
    "    \n",
    "    s_rgb = np.dstack((s_binary,s_binary,s_binary))*255\n",
    "    l_rgb = np.dstack((l_binary,l_binary,l_binary))*255\n",
    "    column = np.concatenate((l_rgb,s_rgb,rgb_combined),axis=0)\n",
    "    analyse_grad_color = np.concatenate((analyse_grad,column),axis=1)\n",
    "    return binary_combined, rgb_combined, analyse_grad_color\n",
    "\n",
    "images = glob.glob('output_images/undist*.jpg')\n",
    "for idx,fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    binary_combined, rgb_combined, analyse_grad_color = combine_grad_color_thresh(img)\n",
    "\n",
    "    cv2.imwrite('output_images/pipeline' + str(idx) + '.jpg', binary_combined*255)\n",
    "    cv2.imwrite('output_images/analyse_grad_color' + str(idx) + '.jpg', analyse_grad_color)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def process_perspective(image):\n",
    "    # to get an image from the top view perspective\n",
    "    imshape = image.shape\n",
    "    cut_y = 60\n",
    "    h_mod = imshape[0]*0.932-cut_y\n",
    "    h_trapezoid = h_mod*0.47\n",
    "    a_trapezoid = imshape[1]*(h_mod/2-h_trapezoid)/(h_mod/2)\n",
    "\n",
    "    vertices_mask= np.array([[(0,imshape[0]-cut_y),(imshape[1]/2-a_trapezoid/2, imshape[0]-h_trapezoid), (imshape[1]/2+a_trapezoid/2, imshape[0]-h_trapezoid), (imshape[1],imshape[0]-cut_y)]], dtype=np.float32)\n",
    "    h_new = imshape[0]*3\n",
    "    w_new = imshape[1]*1\n",
    "    vertices_dst= np.array([[(0,h_new),(0,0), (w_new, 0), (w_new,h_new)]], dtype=np.float32)\n",
    "\n",
    "    matrix_transform = cv2.getPerspectiveTransform(vertices_mask,vertices_dst)\n",
    "    image_dst = cv2.warpPerspective(image,matrix_transform,(w_new,h_new),flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    matrix_transform_back = cv2.getPerspectiveTransform(vertices_dst,vertices_mask)\n",
    "\n",
    "    return image_dst, matrix_transform_back\n",
    "\n",
    "images = glob.glob('output_images/undist*.jpg')\n",
    "for idx,fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    binary_combined, rgb_combined, analyse_grad_color = combine_grad_color_thresh(img)\n",
    "    processed_analyse, matrix_transform_back = process_perspective(binary_combined)\n",
    "\n",
    "    \n",
    "    cv2.imwrite('output_images/perspective' + str(idx) + '.jpg', processed_analyse*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "099c1e2e-042e-4f57-8f38-4a19b4e12274"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "nbpresent": {
     "id": "61059bbd-4974-49ec-902d-3fd35a42389b"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064.10112545 m 636.724605711 m\n",
      "4213.41926392 m 891.884145517 m\n",
      "365.803946042 m 509.785479631 m\n",
      "2866.34481345 m 3087.31597437 m\n",
      "731.459426912 m 711.841351071 m\n",
      "1200.04099023 m 2123.78330977 m\n",
      "477.493395438 m 533.90792798 m\n",
      "423.235255939 m 354.32140537 m\n"
     ]
    }
   ],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return dir_binary\n",
    "\n",
    "def process_grad_thresholds(image):\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 9 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(30, 255))\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=15, mag_thresh=(30, 255))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined1 = np.zeros_like(dir_binary)\n",
    "    combined2 = np.zeros_like(dir_binary)\n",
    "    combined3 = np.zeros_like(dir_binary)\n",
    "    combined1[(gradx == 1)] = 1\n",
    "    combined2[((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined3 = cv2.bitwise_or(combined1, combined2)\n",
    "    #combined = np.uint8(np.rint(combined3*255))\n",
    "    result = gradx\n",
    "    \n",
    "#    show(gradx,0)\n",
    "#    show(grady,0)\n",
    "#   show(mag_binary,0)\n",
    "#    show(dir_binary,0)\n",
    "#    show(combined,0)\n",
    "\n",
    "    image_poly = np.copy(image)\n",
    "    mask_poly = np.zeros_like(gradx)\n",
    "    cut_y, vertices_poly = region_masking_vertices(image.shape)\n",
    "    vertices_poly = np.int32(vertices_poly)\n",
    "    cv2.fillPoly(mask_poly, vertices_poly, 1)\n",
    "    image_poly[mask_poly == 0,:] = [0, 0, 0]\n",
    "    image_poly = cv2.addWeighted(image_poly,0.5,image,0.5,1)\n",
    "\n",
    "    row1 = np.concatenate((image_poly,cv2.cvtColor(gradx*255,cv2.COLOR_GRAY2BGR)),axis=1)\n",
    "    row2 = np.concatenate((mag_binary,dir_binary),axis=1)\n",
    "    row2 = np.uint8(np.rint(row2*255))\n",
    "    row2 = cv2.cvtColor(row2,cv2.COLOR_GRAY2BGR)\n",
    "    row3 = np.concatenate((combined2,result),axis=1)\n",
    "    row3 = np.uint8(np.rint(row3*255))\n",
    "    row3 = cv2.cvtColor(row3,cv2.COLOR_GRAY2BGR)\n",
    "    processed_analyse = np.concatenate((row1,row2,row3),axis=0)\n",
    "    \n",
    "#    show(processed_analyse)\n",
    "    return processed_analyse, result\n",
    "\n",
    "def color_thresh(img, s_thresh=(170, 255), l_thresh=(170, 255)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "        \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    return s_binary, l_binary\n",
    "\n",
    "def combine_grad_color_thresh(img):\n",
    "    analyse_grad,grad_binary=process_grad_thresholds(img)\n",
    "    s_binary, l_binary = color_thresh(img)\n",
    "    \n",
    "    rgb_combined = np.dstack(( np.zeros_like(grad_binary), grad_binary, s_binary)) * 255\n",
    "    binary_combined = np.zeros_like(grad_binary)\n",
    "    binary_combined[(grad_binary == 1) | (s_binary == 1)] = 1\n",
    "    \n",
    "    s_rgb = np.dstack((s_binary,s_binary,s_binary))*255\n",
    "    l_rgb = np.dstack((l_binary,l_binary,l_binary))*255\n",
    "    column = np.concatenate((s_rgb,rgb_combined),axis=1)\n",
    "    analyse_grad_color = np.concatenate((analyse_grad,column),axis=0)\n",
    "    return binary_combined, rgb_combined, analyse_grad_color\n",
    "\n",
    "def region_masking_vertices(imshape):\n",
    "    cut_y = 60\n",
    "    cut_b_trapezoid = 100\n",
    "    h_mod = imshape[0]*0.95-cut_y\n",
    "    h_trapezoid = h_mod*0.43\n",
    "    a_trapezoid = (imshape[1]-2*cut_b_trapezoid)*(h_mod/2-h_trapezoid)/(h_mod/2)\n",
    "    vertices_mask= np.array([[(cut_b_trapezoid,imshape[0]-cut_y),(imshape[1]/2-a_trapezoid/2, imshape[0]-h_trapezoid), (imshape[1]/2+a_trapezoid/2, imshape[0]-h_trapezoid), (imshape[1]-cut_b_trapezoid,imshape[0]-cut_y)]], dtype=np.float32)\n",
    "    vertices_mask = np.rint(vertices_mask)\n",
    "    return cut_y, vertices_mask\n",
    "\n",
    "def process_perspective(image):\n",
    "    # to get an image from the top view perspective\n",
    "    imshape = image.shape\n",
    "\n",
    "    cut_y, vertices_mask = region_masking_vertices(imshape)\n",
    "    \n",
    "    h_new = imshape[0]*4\n",
    "    w_new = imshape[1]*1\n",
    "    vertices_dst= np.array([[(0,h_new),(0,0), (w_new, 0), (w_new,h_new)]], dtype=np.float32)\n",
    "    \n",
    "    matrix_transform = cv2.getPerspectiveTransform(vertices_mask,vertices_dst)\n",
    "    image_dst = cv2.warpPerspective(image,matrix_transform,(w_new,h_new),flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    matrix_transform_back = cv2.getPerspectiveTransform(vertices_dst,vertices_mask)\n",
    "\n",
    "    return image_dst, matrix_transform_back\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 0*ploty**2 + 1*ploty\n",
    "        right_fitx = 0*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    idx_inscope_left_fitx = (left_fitx >= 0) & (left_fitx < (binary_warped.shape[1]-0.5))\n",
    "    idx_inscope_right_fitx = (right_fitx >= 0) & (right_fitx < (binary_warped.shape[1]-0.5))\n",
    "    # converts float arrays to integer arrays\n",
    "    ploty = np.rint(ploty).astype(int)\n",
    "    left_fitx = np.rint(left_fitx).astype(int)\n",
    "    right_fitx = np.rint(right_fitx).astype(int)\n",
    "    #prin(np.max(right_fitx[idx_inscope_right_fitx]))\n",
    "   # show(binary_warped)\n",
    "    \n",
    "    out_img[ploty[idx_inscope_left_fitx], left_fitx[idx_inscope_left_fitx]] = [255, 255, 255]\n",
    "    out_img[ploty[idx_inscope_right_fitx], right_fitx[idx_inscope_right_fitx]] = [255, 255, 255]\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    yscale = 30/2880 # meters per pixel in y dimension\n",
    "    xscale = 3.7/800 # meters per pixel in x dimension\n",
    "    afactor = xscale/yscale**2\n",
    "    bfactor = xscale/yscale\n",
    "    aleftscaled = left_fit[0]*afactor\n",
    "    bleftscaled = left_fit[1]*bfactor\n",
    "    arightscaled = right_fit[0]*afactor\n",
    "    brightscaled = right_fit[1]*bfactor\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval_scaled = np.max(ploty)*yscale\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*aleftscaled*y_eval_scaled + bleftscaled)**2)**1.5) / np.absolute(2*aleftscaled)\n",
    "    right_curverad = ((1 + (2*arightscaled*y_eval_scaled + brightscaled)**2)**1.5) / np.absolute(2*arightscaled)\n",
    "    print(left_curverad,'m', right_curverad,'m')\n",
    "   \n",
    "    return out_img#,left_curverad,right_curverad\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  \n",
    "\n",
    "images = glob.glob('output_images/undist*.jpg')\n",
    "for idx,fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    binary_combined, rgb_combined, analyse_grad_color = combine_grad_color_thresh(img)\n",
    "    processed_analyse, matrix_transform_back = process_perspective(binary_combined)\n",
    "    perspec_rgb, matrix_transform_back = process_perspective(rgb_combined)\n",
    "    #show(processed_perspective)\n",
    "    left_lane = Line()\n",
    "    right_lane = Line()\n",
    "    out_img = fit_polynomial(processed_analyse)\n",
    "    #column = cv2.addWeighted(np.float64(out_img), 0.5, perspec_rgb, 0.5, 0)\n",
    "    analyse_overall = np.concatenate((analyse_grad_color,perspec_rgb,out_img),axis=1)\n",
    "    \n",
    "    cv2.imwrite('output_images/sliding_histo'+str(idx)+'.jpg',out_img)\n",
    "    cv2.imwrite('output_images/analyse_overall'+str(idx)+'.jpg',analyse_overall)\n",
    "    #show(out_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our image - this should be a new frame since last time!\n",
    "binary_warped = mpimg.imread('warped_example.jpg')\n",
    "\n",
    "# Polynomial fit values from the previous frame\n",
    "# Make sure to grab the actual values from the previous step in your project!\n",
    "left_fit = np.array([ 2.13935315e-04, -3.77507980e-01,  4.76902175e+02])\n",
    "right_fit = np.array([4.17622148e-04, -4.93848953e-01,  1.11806170e+03])\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "     ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "result = search_around_poly(binary_warped)\n",
    "\n",
    "# View your output\n",
    "plt.imshow(result)\n",
    "\n",
    "\n",
    "Sanity Check\n",
    "Ok, so your algorithm found some lines. Before moving on, you should check that the detection makes sense. To confirm that your detected lane lines are real, you might consider:\n",
    "\n",
    "Checking that they have similar curvature\n",
    "Checking that they are separated by approximately the right distance horizontally\n",
    "Checking that they are roughly parallel\n",
    "\n",
    "Look-Ahead Filter\n",
    "\n",
    "Reset\n",
    "\n",
    "Smoothing\n",
    "\n",
    "Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return dir_binary\n",
    "\n",
    "def process_grad_thresholds(image):\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 9 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(30, 255))\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=15, mag_thresh=(30, 255))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined1 = np.zeros_like(dir_binary)\n",
    "    combined2 = np.zeros_like(dir_binary)\n",
    "    combined3 = np.zeros_like(dir_binary)\n",
    "    combined1[(gradx == 1)] = 1\n",
    "    combined2[((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined3 = cv2.bitwise_or(combined1, combined2)\n",
    "    #combined = np.uint8(np.rint(combined3*255))\n",
    "    result = gradx\n",
    "    \n",
    "#    show(gradx,0)\n",
    "#    show(grady,0)\n",
    "#   show(mag_binary,0)\n",
    "#    show(dir_binary,0)\n",
    "#    show(combined,0)\n",
    "\n",
    "    image_poly = np.copy(image)\n",
    "    mask_poly = np.zeros_like(gradx)\n",
    "    cut_y, vertices_poly = region_masking_vertices(image.shape)\n",
    "    vertices_poly = np.int32(vertices_poly)\n",
    "    cv2.fillPoly(mask_poly, vertices_poly, 1)\n",
    "    image_poly[mask_poly == 0,:] = [0, 0, 0]\n",
    "    image_poly = cv2.addWeighted(image_poly,0.5,image,0.5,1)\n",
    "\n",
    "    row1 = np.concatenate((image_poly,cv2.cvtColor(gradx*255,cv2.COLOR_GRAY2BGR)),axis=1)\n",
    "    row2 = np.concatenate((mag_binary,dir_binary),axis=1)\n",
    "    row2 = np.uint8(np.rint(row2*255))\n",
    "    row2 = cv2.cvtColor(row2,cv2.COLOR_GRAY2BGR)\n",
    "    row3 = np.concatenate((combined2,result),axis=1)\n",
    "    row3 = np.uint8(np.rint(row3*255))\n",
    "    row3 = cv2.cvtColor(row3,cv2.COLOR_GRAY2BGR)\n",
    "    processed_analyse = np.concatenate((row1,row2,row3),axis=0)\n",
    "    \n",
    "#    show(processed_analyse)\n",
    "    return processed_analyse, result\n",
    "\n",
    "def color_thresh(img, s_thresh=(170, 255), l_thresh=(170, 255)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "        \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    return s_binary, l_binary\n",
    "\n",
    "def combine_grad_color_thresh(img):\n",
    "    analyse_grad,grad_binary=process_grad_thresholds(img)\n",
    "    s_binary, l_binary = color_thresh(img)\n",
    "    \n",
    "    rgb_combined = np.dstack(( np.zeros_like(grad_binary), grad_binary, s_binary)) * 255\n",
    "    binary_combined = np.zeros_like(grad_binary)\n",
    "    binary_combined[(grad_binary == 1) | (s_binary == 1)] = 1\n",
    "    \n",
    "    s_rgb = np.dstack((s_binary,s_binary,s_binary))*255\n",
    "    l_rgb = np.dstack((l_binary,l_binary,l_binary))*255\n",
    "    column = np.concatenate((s_rgb,rgb_combined),axis=1)\n",
    "    analyse_grad_color = np.concatenate((analyse_grad,column),axis=0)\n",
    "    return binary_combined, rgb_combined, analyse_grad_color\n",
    "\n",
    "def region_masking_vertices(imshape):\n",
    "    cut_y = 60\n",
    "    cut_b_trapezoid = 100\n",
    "    h_mod = imshape[0]*0.95-cut_y\n",
    "    h_trapezoid = h_mod*0.43\n",
    "    a_trapezoid = (imshape[1]-2*cut_b_trapezoid)*(h_mod/2-h_trapezoid)/(h_mod/2)\n",
    "    vertices_mask= np.array([[(cut_b_trapezoid,imshape[0]-cut_y),(imshape[1]/2-a_trapezoid/2, imshape[0]-h_trapezoid), (imshape[1]/2+a_trapezoid/2, imshape[0]-h_trapezoid), (imshape[1]-cut_b_trapezoid,imshape[0]-cut_y)]], dtype=np.float32)\n",
    "    vertices_mask = np.rint(vertices_mask)\n",
    "    return cut_y, vertices_mask\n",
    "\n",
    "def process_perspective(image):\n",
    "    # to get an image from the top view perspective\n",
    "    imshape = image.shape\n",
    "\n",
    "    cut_y, vertices_mask = region_masking_vertices(imshape)\n",
    "    \n",
    "    h_new = imshape[0]*4\n",
    "    w_new = imshape[1]*1\n",
    "    vertices_dst= np.array([[(0,h_new),(0,0), (w_new, 0), (w_new,h_new)]], dtype=np.float32)\n",
    "    \n",
    "    matrix_transform = cv2.getPerspectiveTransform(vertices_mask,vertices_dst)\n",
    "    image_dst = cv2.warpPerspective(image,matrix_transform,(w_new,h_new),flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    matrix_transform_back = cv2.getPerspectiveTransform(vertices_dst,vertices_mask)\n",
    "\n",
    "    return image_dst, matrix_transform_back\n",
    "\n",
    "def find_lane_pixels_sliding_windows(out_img,binary_warped,nonzeroy,nonzerox):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "   \n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "    \n",
    "    return left_lane_inds, right_lane_inds, out_img\n",
    "\n",
    "def find_lane_pixels_last_fit(nonzeroy,nonzerox):\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    left_fit = np.copy(Left_Lane.fit_stack)\n",
    "    right_fit = np.copy(Right_Lane.fit_stack)\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    return left_lane_inds, right_lane_inds\n",
    "\n",
    "    \n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])   \n",
    "\n",
    "    print(Left_Lane.fit_stack[0] == False)\n",
    "\n",
    "    if Left_Lane.fit_stack[0] == False:\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "    else:\n",
    "        left_lane_inds, right_lane_inds = find_lane_pixels_last_fit(nonzeroy,nonzerox)\n",
    "        \n",
    "    set_trace()\n",
    "    minpix_lane = 300\n",
    "    counter_limit = 5\n",
    "    if (len(left_lane_inds)<=minpix_lane | len(right_lane_inds)<=minpix_lane):        \n",
    "        left_lane_inds_sw, right_lane_inds_sw, out_img = find_lane_pixels_sliding_windows(out_img,binary_warped,nonzeroy,nonzerox)\n",
    "        if len(left_lane_inds)<=minpix_lane:\n",
    "            if Left_Lane.not_detected_counter >= counter_limit:\n",
    "                left_lane_inds = np.copy(left_lane_inds_sw)\n",
    "                \n",
    "        if len(left_lane_inds) > minpix_lane:\n",
    "            Left_Lane.inds_stack = np.copy(left_lane_inds)\n",
    "            Left_Lane.not_detected_counter = 0\n",
    "        else:\n",
    "            left_lane_inds = Left_Lane.inds_stack\n",
    "            Left_Lane.not_detected_counter += 1\n",
    "            \n",
    "        if len(right_lane_inds)<=minpix_lane:\n",
    "            if Right_Lane.not_detected_counter >= counter_limit:\n",
    "                right_lane_inds = np.copy(right_lane_inds_sw)\n",
    "                \n",
    "        if len(right_lane_inds) > minpix_lane:\n",
    "            Right_Lane.inds_stack = np.copy(right_lane_inds)\n",
    "            Right_Lane.not_detected_counter = 0\n",
    "        else:\n",
    "            right_lane_inds = np.copy(Right_Lane.inds_stack)\n",
    "            Right_Lane.not_detected_counter += 1\n",
    "    else:\n",
    "        Left_Lane.inds_stack = np.copy(left_lane_inds)\n",
    "        Left_Lane.not_detected_counter = 0\n",
    "        Right_Lane.inds_stack = np.copy(right_lane_inds)\n",
    "        Right_Lane.not_detected_counter = 0\n",
    "                        \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "            \n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    Left_Lane.fit_stack = np.copy(left_fit)\n",
    "    Right_Lane.fit_stack = np.copy(right_fit)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 0*ploty**2 + 1*ploty\n",
    "        right_fitx = 0*ploty**2 + 1*ploty\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    idx_inscope_left_fitx = (left_fitx >= 0) & (left_fitx < (binary_warped.shape[1]-0.5))\n",
    "    idx_inscope_right_fitx = (right_fitx >= 0) & (right_fitx < (binary_warped.shape[1]-0.5))\n",
    "    # converts float arrays to integer arrays\n",
    "    ploty = np.rint(ploty).astype(int)\n",
    "    left_fitx = np.rint(left_fitx).astype(int)\n",
    "    right_fitx = np.rint(right_fitx).astype(int)\n",
    "    #prin(np.max(right_fitx[idx_inscope_right_fitx]))\n",
    "   # show(binary_warped)\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    out_img[ploty[idx_inscope_left_fitx], left_fitx[idx_inscope_left_fitx]] = [255, 255, 255]\n",
    "    out_img[ploty[idx_inscope_right_fitx], right_fitx[idx_inscope_right_fitx]] = [255, 255, 255]\n",
    "    result = out_img       \n",
    "        \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    yscale = 30/2880 # meters per pixel in y dimension\n",
    "    xscale = 3.7/800 # meters per pixel in x dimension\n",
    "    afactor = xscale/yscale**2\n",
    "    bfactor = xscale/yscale\n",
    "    aleftscaled = left_fit[0]*afactor\n",
    "    bleftscaled = left_fit[1]*bfactor\n",
    "    arightscaled = right_fit[0]*afactor\n",
    "    brightscaled = right_fit[1]*bfactor\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval_scaled = np.max(ploty)*yscale\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*aleftscaled*y_eval_scaled + bleftscaled)**2)**1.5) / np.absolute(2*aleftscaled)\n",
    "    right_curverad = ((1 + (2*arightscaled*y_eval_scaled + brightscaled)**2)**1.5) / np.absolute(2*arightscaled)\n",
    "    print(left_curverad,'m', right_curverad,'m')\n",
    "   \n",
    "    return result,ploty,left_fitx,right_fitx\n",
    "\n",
    "def unwarp(warped,ploty,left_fitx,right_fitx,Minv,image):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "#    pts = np.hstack((pts_left, pts_right))\n",
    "    pts = np.concatenate((pts_left,pts_right),axis=1)\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "#    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.fillPoly(warp_zero, pts, [0,255, 0])\n",
    "\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(warp_zero, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        #result of sanity check\n",
    "        self.sanity = False\n",
    "        #stack for indices\n",
    "        self.inds_stack = [np.array([0,0,1])]\n",
    "        #counter for not detected lane\n",
    "        self.not_detected_counter = 0\n",
    "        #stack for fit\n",
    "        self.fit_stack = [np.array(False)]\n",
    "        \n",
    "def sanity_check(left_curverad,right_curverad,left_fitx,rigth_fitx):\n",
    "    if numpy.absolute(left_curverad-right_curverad)<=100:\n",
    "        if (rigth_fitx[1]-left_fitx[1])>=700 & (rigth_fitx[1]-left_fitx[1])<=900:\n",
    "            if (rigth_fitx[-1]-left_fitx[-1])>=700 & (rigth_fitx[-1]-left_fitx[-1])<=900:\n",
    "                if numpy.absolute((rigth_fitx[-1]-left_fitx[-1]) - (rigth_fitx[-1]-left_fitx[-1]))<=100:\n",
    "                    x = 1;\n",
    "\n",
    "        \n",
    "def process_image(img):\n",
    "    binary_combined, rgb_combined, analyse_grad_color = combine_grad_color_thresh(img)\n",
    "    processed_analyse, matrix_transform_back = process_perspective(binary_combined)\n",
    "    perspec_rgb, matrix_transform_back = process_perspective(rgb_combined)\n",
    "    out_img,ploty,left_fitx,right_fitx = fit_polynomial(processed_analyse)\n",
    "    unwarped = unwarp(out_img,ploty,left_fitx,right_fitx,matrix_transform_back,img)\n",
    "    analyse_grad_color[:img.shape[0],img.shape[1]:2*img.shape[1],:] = np.copy(unwarped)\n",
    "    analyse_overall = np.concatenate((analyse_grad_color,perspec_rgb,out_img),axis=1)\n",
    "    return analyse_overall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('output_images/undist*.jpg')\n",
    "Left_Lane = Line()\n",
    "Right_Lane = Line()\n",
    "for idx,fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    analyse_overall = process_image(img)\n",
    "    \n",
    "    cv2.imwrite('output_images/analyse_overall'+str(idx)+'.jpg',analyse_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "video = 'challenge_video.mp4'\n",
    "output = 'out_put_' + video\n",
    "clip1 = VideoFileClip(video)\n",
    "Left_Lane = Line()\n",
    "Right_Lane = Line()\n",
    "clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
